\section{Main Theorem}
In this section, we present the main theory on approximation error for both one-pass and two pass algorithms under two scenarios. One scenario is low rank approximation (algorithm \ref{alg:one_pass_low_rank_appro}, algorithm \ref{alg:two_pass_low_rank_appro}) and the other is fix rank approximation using Tucker decomposition (Algorithm \ref{alg:one_pass_fix_rank_appro}, algorithm \ref{alg:two_pass_fix_rank_appro}). 
\begin{thm}
\label{thm: low_rank_err}
let  $\hat{\mathscr{X}}_1$, $\hat{\mathscr{X}}_2$ be the output from function OnePassLowRankRecovery and TwoPassLowRankRecovery in algorithm \ref{alg:one_pass_low_rank_appro} and algorithm \ref{alg:two_pass_low_rank_appro} respectively. Assuming all random test matrices $\mathbf{\Omega}_n, \mathbf{\Phi}_n, 1\le n\le N$ are standard Gaussian random matrix, for any natural number $1\le \rho< k$, 
\begin{equation}
\mathbb{E}\| \mathscr{X} - \hat{\mathscr{X}}_2 \|_F^2 \leq  \sum_{n=1}^N \left(1+\frac{k}{k-\rho-1}\right)(\tau^{(n)}_\rho)^2, 
\end{equation}
and assuming $s>2k$, 
\begin{equation}
\mathbb{E}\| \mathscr{X} - \hat{\mathscr{X}}_1 \|_F^2  \le    \left(1+\frac{k}{s-k-1}\right) \sum_{n=1}^N \left(1+\frac{k}{k-\rho-1}\right)(\tau^{(n)}_\rho)^2. 
\end{equation}
\end{thm}
