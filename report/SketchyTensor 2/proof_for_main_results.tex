


\section{Proof for Main Results}
\subsection{Proof for Theorem \ref{thm: low_rank_err}}
Let $\tilde{\mathscr{X}}$ denote the compressed tensor, 
\begin{equation}
\label{eq:definition_of_compression_tensor}
\tilde{\mathscr{X}} = \mathscr{X}\times_1  \mathbf{Q}_1\mathbf{Q}_1^\top \times \cdots \times_N \mathbf{Q}_N\mathbf{Q}_N^\top.
\end{equation}
Error bound for $\hat{\mathscr{X}}_2$ from two pass algorithm is directly from lemma \ref{lemma: compression_error} noticing the compression tensor is exactly the output of TwoPassLowRank in algorithm \ref{alg:two_pass_low_rank_appro}: $\tilde{\mathscr{X}} = \hat{\mathscr{X}}_2$. Now we turn to the proof for one pass. \par 
We claim that 
\begin{equation}
\label{eq:inner_zero}
\begin{aligned}
&\langle \hat{\mathscr{X}}_1 - \Tilde{\mathscr{X}}, \Tilde{\mathscr{X}} - \mathscr{X} \rangle = 0. 
\end{aligned}
\end{equation}
To see why, for $1 \leq n \leq N$, let 
\begin{equation} 
\label{eq:definition_Y_n}
\mathscr{Y}_n = \mathscr{X} \times_1 \mathbf{Q}_1\mathbf{Q}_1^\top \times_2 \cdots \times_n \mathbf{Q}_n\mathbf{Q}_n^\top,
\end{equation}
and $\mathscr{Y}_0 = \mathscr{X}$. 
Then 
\begin{equation}\label{eq: y_diff}
\begin{aligned}
\mathscr{X}-\tilde{\mathscr{X}} = \mathscr{Y}_0 - \mathscr{Y}_N= \sum_{n=0}^{N-1} (\mathscr{Y}_n - \mathscr{Y}_{(n+1)}).
\end{aligned}
\end{equation}
Besides, with formula of $\hat{\mathscr{X}}_1$ in algorithm \ref{alg:one_pass_low_rank_appro} and the definition of $\tilde{\mathscr{X}}_1$, it is not hard to show that 
\begin{equation}
\begin{aligned}
\mathscr{\hat{X}}_1-\tilde{\mathscr{X}}= (\mathscr{W}-\mathscr{X}\times_1 \mathbf{Q}_1^\top \times \times_N \mathbf{Q}_n^\top)  \times_1 \mathbf{Q}_1 \dots \times_N \mathbf{Q}_N. 
\end{aligned}
\end{equation}
For any $0\le n< N$, 
\begin{equation}
\mathscr{Y}_n-\mathscr{Y}_{n+1} = \mathscr{Y}_{n} \times_{(n+1)} (\mathbf{I} - \mathbf{Q}_{n+1}\mathbf{Q}^\top_{n+1}).
\end{equation}
Then with \eqref{eq:F_norm_equivalent}, 
\begin{equation}
\begin{aligned}
&\langle \mathscr{Y}_n-\mathscr{Y}_{n+1}, \mathscr{\hat{X}}-\tilde{\mathscr{X}}\rangle = \langle (\mathbf{I} - \mathbf{Q}_{n+1}\mathbf{Q}^\top_{n+1}) \mathbf{Y}_{n}^{(n)},  \mathbf{Q}_{n+1}\mathbf{B}^{(n)}\rangle \\
& = \rm{Tr}(\mathbf{Y}_{n}^{(n)} (\mathbf{I} - \mathbf{Q}_{n+1}\mathbf{Q}^\top_{n+1})\mathbf{Q}_{n+1}\mathbf{B}^{(n)} )=0 , 
\end{aligned}
\end{equation}
where $\mathbf{B}^{(n)}$ is the mode nth unfolding of tensor $\mathscr{B}$ defined as 
\begin{equation}
\mathscr{B} = (\mathscr{W}-\mathscr{X}\times_1 \mathbf{Q}_1^\top \times \times_N \mathbf{Q}_n^\top)  \times_1 \mathbf{Q}_1 \dots \times_n \mathbf{Q}_n \times_{n+1}  \mathbf{Q}_{n+1} \dots \times_N   \mathbf{Q}_{N}. 
\end{equation}
Then \eqref{eq:inner_zero} indicates 
\begin{equation}
 \mathbb{E}\| \hat{\mathscr{X}} - \mathscr{X} \|_F^2 = \mathbb{E}\| \hat{\mathscr{X}} - \Tilde{\mathscr{X}}\|_F^2 + \|\Tilde{\mathscr{X}} - \mathscr{X} \|_F^2. 
\end{equation}
Applying error bound in lemma \ref{lemma: compression_error} for the first term and error bound in lemma \ref{lemma:}, we could finish proof. 


